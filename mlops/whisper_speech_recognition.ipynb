{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é Whisper\n",
        "\n",
        "–≠—Ç–æ—Ç notebook –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å `whisper-small` –æ—Ç OpenAI –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π.\n",
        "\n",
        "## –ó–∞–¥–∞—á–∞:\n",
        "1. –í–∑—è—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å https://disk.yandex.ru/d/v2Hipv7XG4fEDQ\n",
        "2. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å whisper-small –∏–∑ HuggingFace \n",
        "3. –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è 10 —Å–ª—É—á–∞–π–Ω—ã—Ö –∞—É–¥–∏–æ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "!pip install torch transformers soundfile datasets requests tqdm ffmpeg-python torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "import os\n",
        "import random\n",
        "import logging\n",
        "import zipfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import numpy as np\n",
        "from IPython.display import Audio, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
        "MODEL_NAME = \"openai/whisper-small\"\n",
        "SAMPLE_RATE = 16000\n",
        "MAX_AUDIO_LENGTH = 30  # —Å–µ–∫—É–Ω–¥\n",
        "RANDOM_SEED = 42\n",
        "NUM_SAMPLES = 10\n",
        "DATASET_DIR = \"dataset\"\n",
        "\n",
        "print(f\"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\")\n",
        "print(f\"   –ú–æ–¥–µ–ª—å: {MODEL_NAME}\")\n",
        "print(f\"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {SAMPLE_RATE} Hz\")\n",
        "print(f\"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {MAX_AUDIO_LENGTH} —Å–µ–∫\")\n",
        "print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {NUM_SAMPLES}\")\n",
        "print(f\"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞: {DATASET_DIR}\")\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ —Å torchaudio (—Ç–æ–ª—å–∫–æ –∑–∞–≥—Ä—É–∑–∫–∞)\n",
        "def load_audio_with_torchaudio(audio_path: str):\n",
        "    \"\"\"\n",
        "    –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º torchaudio –¥–ª—è –ø–µ—Ä–µ—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "    \"\"\"\n",
        "    print(f\"üéµ –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å torchaudio: {os.path.basename(audio_path)}\")\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª\n",
        "    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac'}\n",
        "    file_ext = Path(audio_path).suffix.lower()\n",
        "    \n",
        "    if file_ext not in audio_extensions:\n",
        "        print(f\"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_ext}\")\n",
        "        return None, None\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞\n",
        "    filename_lower = os.path.basename(audio_path).lower()\n",
        "    if any(skip_word in filename_lower for skip_word in ['tsv', 'csv', 'txt', 'json', 'xml']):\n",
        "        print(f\"‚ùå –§–∞–π–ª –ø–æ—Ö–æ–∂ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π: {os.path.basename(audio_path)}\")\n",
        "        return None, None\n",
        "    \n",
        "    try:\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é torchaudio\n",
        "        wav, sr = torchaudio.load(audio_path)\n",
        "        print(f\"‚úÖ –ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {wav.shape}, —á–∞—Å—Ç–æ—Ç–∞: {sr} Hz\")\n",
        "        \n",
        "        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª –µ—Å–ª–∏ –∞—É–¥–∏–æ —Å—Ç–µ—Ä–µ–æ\n",
        "        if wav.shape[0] > 1:\n",
        "            wav = wav[0:1, :]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª\n",
        "            print(f\"üìä –í–∑—è—Ç –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª: {wav.shape}\")\n",
        "        \n",
        "        # –ø–µ—Ä–µ—Å—ç–º–ø–ª–∏—Ä—É–π—Ç–µ –∏–º–µ—é—â–∏–µ—Å—è –∞—É–¥–∏–æ –≤ 16 kHz - –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –Ω–∏–∂–µ, –º–æ–∂–µ—Ç–µ –µ–≥–æ –º–µ–Ω—è—Ç—å\n",
        "        if sr != 16000:\n",
        "            print(f\"üîÑ –ü–µ—Ä–µ—Å—ç–º–ø–ª–∏—Ä—É–µ–º —Å {sr} Hz –Ω–∞ 16000 Hz\")\n",
        "            wav = torchaudio.functional.resample(wav, orig_freq=sr, new_freq=16000)\n",
        "            sr = 16000\n",
        "            print(f\"‚úÖ –ü–µ—Ä–µ—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {wav.shape}\")\n",
        "        \n",
        "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∞—É–¥–∏–æ\n",
        "        max_samples = MAX_AUDIO_LENGTH * sr\n",
        "        if wav.shape[1] > max_samples:\n",
        "            wav = wav[:, :max_samples]\n",
        "            print(f\"‚ö†Ô∏è  –ê—É–¥–∏–æ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ {MAX_AUDIO_LENGTH} —Å–µ–∫\")\n",
        "        \n",
        "        return wav, sr\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {audio_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ —Å torchaudio –≥–æ—Ç–æ–≤–∞!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{DATASET_DIR}' —Å–æ–∑–¥–∞–Ω–∞\")\n",
        "print(f\"üì• –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å https://disk.yandex.ru/d/v2Hipv7XG4fEDQ\")\n",
        "print(f\"üìÇ –ò –ø–æ–º–µ—Å—Ç–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É '{DATASET_DIR}/'\")\n",
        "print(f\"üéµ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .wav, .mp3, .flac, .ogg, .m4a, .aac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ dataset\n",
        "print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ dataset:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if os.path.exists(DATASET_DIR):\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(DATASET_DIR):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            file_ext = Path(file).suffix.lower()\n",
        "            \n",
        "            all_files.append({\n",
        "                'name': file,\n",
        "                'path': file_path,\n",
        "                'size': file_size,\n",
        "                'ext': file_ext\n",
        "            })\n",
        "    \n",
        "    print(f\"üìä –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {len(all_files)}\")\n",
        "    \n",
        "    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º\n",
        "    extensions = {}\n",
        "    for file_info in all_files:\n",
        "        ext = file_info['ext'] or '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'\n",
        "        if ext not in extensions:\n",
        "            extensions[ext] = []\n",
        "        extensions[ext].append(file_info)\n",
        "    \n",
        "    print(f\"\\nüìã –§–∞–π–ª—ã –ø–æ —Ç–∏–ø–∞–º:\")\n",
        "    for ext, files in extensions.items():\n",
        "        print(f\"   {ext}: {len(files)} —Ñ–∞–π–ª–æ–≤\")\n",
        "        for file_info in files[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ñ–∞–π–ª–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞\n",
        "            size_mb = file_info['size'] / (1024 * 1024)\n",
        "            print(f\"      ‚Ä¢ {file_info['name']} ({size_mb:.2f} MB)\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"      ... –∏ –µ—â–µ {len(files) - 3} —Ñ–∞–π–ª–æ–≤\")\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
        "    suspicious_files = [f for f in all_files if any(word in f['name'].lower() for word in ['tsv', 'csv', 'txt', 'json', 'xml'])]\n",
        "    if suspicious_files:\n",
        "        print(f\"\\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ (–Ω–µ-–∞—É–¥–∏–æ) —Ñ–∞–π–ª—ã:\")\n",
        "        for file_info in suspicious_files:\n",
        "            print(f\"   ‚Ä¢ {file_info['name']} ({file_info['ext']})\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {DATASET_DIR} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ TSV —Ñ–∞–π–ª–∞\n",
        "import pandas as pd\n",
        "\n",
        "def load_tsv_file(tsv_path: str):\n",
        "    \"\"\"\n",
        "    –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ TSV —Ñ–∞–π–ª–∞\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(tsv_path, sep='\\t', encoding='utf-8')\n",
        "        \n",
        "        print(f\"‚úÖ TSV —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n",
        "        print(f\"üìä –†–∞–∑–º–µ—Ä: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "        print(f\"üìã –°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}\")\n",
        "        \n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ TSV: {e}\")\n",
        "        \n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ TSV —Ñ–∞–π–ª–∞\n",
        "tsv_files = []\n",
        "df = None\n",
        "\n",
        "# –ò—â–µ–º TSV —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ dataset\n",
        "if os.path.exists(DATASET_DIR):\n",
        "    for root, dirs, files in os.walk(DATASET_DIR):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.tsv'):\n",
        "                tsv_path = os.path.join(root, file)\n",
        "                tsv_files.append(tsv_path)\n",
        "                print(f\"üìã –ù–∞–π–¥–µ–Ω TSV —Ñ–∞–π–ª: {file}\")\n",
        "\n",
        "if tsv_files:\n",
        "    print(f\"\\nüîç –ó–∞–≥—Ä—É–∂–∞–µ–º TSV —Ñ–∞–π–ª: {os.path.basename(tsv_files[0])}\")\n",
        "    df = load_tsv_file(tsv_files[0])\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå TSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ dataset\")\n",
        "    print(\"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª urls_normalized.tsv –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ dataset/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞\n",
        "import requests\n",
        "import re\n",
        "\n",
        "def download_from_yandex_disk(public_url: str, output_filename: str = \"urls_normalized.tsv\"):\n",
        "    \"\"\"\n",
        "    –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –ø–æ –ø—É–±–ª–∏—á–Ω–æ–π —Å—Å—ã–ª–∫–µ\n",
        "    \"\"\"\n",
        "    print(f\"üì• –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞...\")\n",
        "    \n",
        "    # API –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏\n",
        "    api_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download\"\n",
        "    \n",
        "    try:\n",
        "        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ\n",
        "        response = requests.get(api_url, params={'public_key': public_url})\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            download_info = response.json()\n",
        "            download_url = download_info['href']\n",
        "            \n",
        "            print(f\"‚úÖ –ü–æ–ª—É—á–µ–Ω–∞ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è\")\n",
        "            \n",
        "            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª\n",
        "            file_response = requests.get(download_url)\n",
        "            \n",
        "            if file_response.status_code == 200:\n",
        "                output_path = os.path.join(DATASET_DIR, output_filename)\n",
        "                \n",
        "                with open(output_path, 'wb') as f:\n",
        "                    f.write(file_response.content)\n",
        "                \n",
        "                print(f\"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω: {output_path}\")\n",
        "                print(f\"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(file_response.content) / 1024:.2f} KB\")\n",
        "                \n",
        "                return output_path\n",
        "            else:\n",
        "                print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {file_response.status_code}\")\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏: {response.status_code}\")\n",
        "            print(f\"–û—Ç–≤–µ—Ç: {response.text}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
        "        return None\n",
        "\n",
        "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± - —Ä—É—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n",
        "def show_manual_download_instructions():\n",
        "    \"\"\"\n",
        "    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è\n",
        "    \"\"\"\n",
        "    print(\"üìã –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –†–£–ß–ù–û–ì–û –°–ö–ê–ß–ò–í–ê–ù–ò–Ø:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"1. –û—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ: https://disk.yandex.ru/d/v2Hipv7XG4fEDQ\")\n",
        "    print(\"2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–°–∫–∞—á–∞—Ç—å' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ\")\n",
        "    print(\"3. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ñ–∞–π–ª –∫–∞–∫ 'urls_normalized.tsv'\")\n",
        "    print(\"4. –ü–æ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É 'dataset/' –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ\")\n",
        "    print(\"5. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫–∏ notebook\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞\n",
        "yandex_url = \"https://disk.yandex.ru/d/v2Hipv7XG4fEDQ\"\n",
        "\n",
        "print(\"üöÄ –ü—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª...\")\n",
        "\n",
        "# –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ–∞–π–ª\n",
        "tsv_path = os.path.join(DATASET_DIR, \"urls_normalized.tsv\")\n",
        "if os.path.exists(tsv_path):\n",
        "    print(f\"‚úÖ –§–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {tsv_path}\")\n",
        "    file_size = os.path.getsize(tsv_path) / 1024\n",
        "    print(f\"üìä –†–∞–∑–º–µ—Ä: {file_size:.2f} KB\")\n",
        "else:\n",
        "    # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å\n",
        "    downloaded_path = download_from_yandex_disk(yandex_url)\n",
        "    \n",
        "    if downloaded_path is None:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚ùå –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å\")\n",
        "        print(\"üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä—É—á–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ:\")\n",
        "        print()\n",
        "        show_manual_download_instructions()\n",
        "        print(\"\\nüîß –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã:\")\n",
        "        print(\"1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ wget —Å –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–æ–π (–µ—Å–ª–∏ –µ—Å—Ç—å)\")\n",
        "        print(\"2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ curl\")\n",
        "        print(\"3. –°–∫–∞—á–∞–π—Ç–µ —á–µ—Ä–µ–∑ –±—Ä–∞—É–∑–µ—Ä\")\n",
        "        print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è\n",
        "print(\"üîß –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ö–û–ú–ê–ù–î–´ –î–õ–Ø –°–ö–ê–ß–ò–í–ê–ù–ò–Ø:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£ –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª:\")\n",
        "print(\"!wget '–ü–†–Ø–ú–ê–Ø_–°–°–´–õ–ö–ê' -O dataset/urls_normalized.tsv\")\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑—É—è curl:\")\n",
        "print(\"!curl -L '–ü–†–Ø–ú–ê–Ø_–°–°–´–õ–ö–ê' -o dataset/urls_normalized.tsv\")\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£ –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–µ:\")\n",
        "print(\"- –û—Ç–∫—Ä–æ–π—Ç–µ https://disk.yandex.ru/d/v2Hipv7XG4fEDQ\")\n",
        "print(\"- –ù–∞–∂–º–∏—Ç–µ –ø—Ä–∞–≤–æ–π –∫–Ω–æ–ø–∫–æ–π –Ω–∞ —Ñ–∞–π–ª ‚Üí '–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É'\")\n",
        "print(\"- –ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ '–°–∫–∞—á–∞—Ç—å' –∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—Å—ã–ª–∫—É –∏–∑ –∞–¥—Ä–µ—Å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏\")\n",
        "\n",
        "print(\"\\n4Ô∏è‚É£ –†—É—á–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ:\")\n",
        "print(\"- –û—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ\")\n",
        "print(\"- –ù–∞–∂–º–∏—Ç–µ '–°–∫–∞—á–∞—Ç—å'\")\n",
        "print(\"- –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É dataset/ –∫–∞–∫ urls_normalized.tsv\")\n",
        "\n",
        "print(\"\\nüí° –ü–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —è—á–µ–π–∫–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ TSV\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ URL –∏–∑ TSV\n",
        "import urllib.request\n",
        "import tempfile\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def download_audio_from_url(url: str, timeout: int = 30):\n",
        "    \"\"\"\n",
        "    –°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –ø–æ URL –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üì• –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ: {url[:50]}...\")\n",
        "        \n",
        "        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
        "        temp_path = temp_file.name\n",
        "        temp_file.close()\n",
        "        \n",
        "        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª\n",
        "        urllib.request.urlretrieve(url, temp_path)\n",
        "        \n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞\n",
        "        file_size = os.path.getsize(temp_path)\n",
        "        print(f\"‚úÖ –°–∫–∞—á–∞–Ω–æ: {file_size / 1024:.2f} KB\")\n",
        "        \n",
        "        return temp_path\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_audio_url_with_whisper(url: str, metadata_row=None):\n",
        "    \"\"\"\n",
        "    –°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –ø–æ URL –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–µ—Ä–µ–∑ Whisper\n",
        "    \"\"\"\n",
        "    print(f\"\\nüéµ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º URL: {url[:60]}...\")\n",
        "    \n",
        "    # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ\n",
        "    temp_audio_path = download_audio_from_url(url)\n",
        "    \n",
        "    if temp_audio_path is None:\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"text\": \"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∞—É–¥–∏–æ\",\n",
        "            \"error\": True\n",
        "        }\n",
        "    \n",
        "    try:\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å torchaudio\n",
        "        wav, sr = load_audio_with_torchaudio(temp_audio_path)\n",
        "        \n",
        "        if wav is None or sr is None:\n",
        "            return {\n",
        "                \"url\": url,\n",
        "                \"text\": \"–û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ\",\n",
        "                \"error\": True\n",
        "            }\n",
        "        \n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞)\n",
        "        if 'processor' not in globals():\n",
        "            global processor, model, device\n",
        "            print(\"ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...\")\n",
        "            processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
        "            model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "            \n",
        "            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫\n",
        "            model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
        "                language=\"russian\", \n",
        "                task=\"transcribe\"\n",
        "            )\n",
        "            \n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "            print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device}\")\n",
        "        \n",
        "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array\n",
        "        audio_array = wav.squeeze().numpy()\n",
        "        \n",
        "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "        input_features = processor(\n",
        "            audio_array, \n",
        "            sampling_rate=sr, \n",
        "            return_tensors=\"pt\"\n",
        "        ).input_features.to(device)\n",
        "        \n",
        "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = model.generate(input_features)\n",
        "        \n",
        "        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        transcription = processor.batch_decode(\n",
        "            predicted_ids, \n",
        "            skip_special_tokens=True\n",
        "        )[0]\n",
        "        \n",
        "        result = {\n",
        "            \"url\": url,\n",
        "            \"text\": transcription.strip(),\n",
        "            \"error\": False,\n",
        "            \"duration\": wav.shape[1] / sr,\n",
        "            \"sample_rate\": sr\n",
        "        }\n",
        "        \n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "        if metadata_row is not None:\n",
        "            for col, value in metadata_row.items():\n",
        "                if pd.notna(value) and col.lower() not in ['url', 'path', 'file']:\n",
        "                    result[f'metadata_{col.lower()}'] = value\n",
        "        \n",
        "        print(f\"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcription[:100]}...\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}\")\n",
        "        return {\n",
        "            \"url\": url,\n",
        "            \"text\": f\"–û–®–ò–ë–ö–ê: {str(e)}\",\n",
        "            \"error\": True\n",
        "        }\n",
        "    \n",
        "    finally:\n",
        "        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "        try:\n",
        "            if temp_audio_path and os.path.exists(temp_audio_path):\n",
        "                os.unlink(temp_audio_path)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "def extract_audio_urls_from_tsv(df):\n",
        "    \"\"\"\n",
        "    –ò–∑–≤–ª–µ–∫–∞–µ—Ç URL-—ã –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –∏–∑ TSV\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        return []\n",
        "    \n",
        "    audio_urls = []\n",
        "    \n",
        "    # –ò—â–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å URL-–∞–º–∏\n",
        "    for col in df.columns:\n",
        "        if any(keyword in col.lower() for keyword in ['url', 'path', 'link', 'audio']):\n",
        "            for idx, url in df[col].dropna().items():\n",
        "                if isinstance(url, str) and ('http' in url or 'storage.mds.yandex.net' in url):\n",
        "                    audio_urls.append({\n",
        "                        'url': url,\n",
        "                        'row_index': idx,\n",
        "                        'metadata': df.iloc[idx].to_dict()\n",
        "                    })\n",
        "    \n",
        "    print(f\"üéµ –ù–∞–π–¥–µ–Ω–æ {len(audio_urls)} –∞—É–¥–∏–æ URL-–æ–≤\")\n",
        "    return audio_urls\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ URL –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ URL –∏–∑ TSV —Ñ–∞–π–ª–∞\n",
        "if 'df' in globals() and df is not None:\n",
        "    print(\"üöÄ –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ URL –∏–∑ TSV...\")\n",
        "    \n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º URL-—ã\n",
        "    audio_urls = extract_audio_urls_from_tsv(df)\n",
        "    \n",
        "    if audio_urls:\n",
        "        print(f\"üìä –ù–∞–π–¥–µ–Ω–æ {len(audio_urls)} –∞—É–¥–∏–æ URL-–æ–≤\")\n",
        "        print(f\"üéØ –ë—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ {min(NUM_SAMPLES, len(audio_urls))} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã URL-–æ–≤\n",
        "        print(f\"\\nüìã –ü—Ä–∏–º–µ—Ä—ã URL-–æ–≤:\")\n",
        "        for i, audio_info in enumerate(audio_urls[:5], 1):\n",
        "            url = audio_info['url']\n",
        "            print(f\"   {i}. {url[:80]}...\")\n",
        "        \n",
        "        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ URL-—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "        import random\n",
        "        random.seed(RANDOM_SEED)\n",
        "        selected_urls = random.sample(audio_urls, min(NUM_SAMPLES, len(audio_urls)))\n",
        "        \n",
        "        print(f\"\\nüé≤ –í—ã–±—Ä–∞–Ω–æ {len(selected_urls)} —Å–ª—É—á–∞–π–Ω—ã—Ö URL-–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n",
        "        \n",
        "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ URL-—ã\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üöÄ –ù–ê–ß–ò–ù–ê–ï–ú –û–ë–†–ê–ë–û–¢–ö–£ –ê–£–î–ò–û –ò–ó TSV\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        url_results = []\n",
        "        \n",
        "        for i, audio_info in enumerate(selected_urls, 1):\n",
        "            print(f\"\\nüìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ {i}/{len(selected_urls)}\")\n",
        "            print(f\"üîó URL: {audio_info['url'][:80]}...\")\n",
        "            \n",
        "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ\n",
        "            result = process_audio_url_with_whisper(\n",
        "                audio_info['url'], \n",
        "                audio_info['metadata']\n",
        "            )\n",
        "            \n",
        "            url_results.append(result)\n",
        "            \n",
        "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "            if not result.get('error', False):\n",
        "                print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: \\\"{result['text'][:100]}...\\\"\")\n",
        "                print(f\"‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result.get('duration', 0):.2f} —Å–µ–∫\")\n",
        "                \n",
        "                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "                metadata_keys = [k for k in result.keys() if k.startswith('metadata_')]\n",
        "                if metadata_keys:\n",
        "                    print(f\"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {len(metadata_keys)} –ø–æ–ª–µ–π\")\n",
        "            else:\n",
        "                print(f\"‚ùå {result['text']}\")\n",
        "            \n",
        "            print(\"-\" * 50)\n",
        "        \n",
        "        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "        successful_results = [r for r in url_results if not r.get('error', False)]\n",
        "        \n",
        "        print(f\"\\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!\")\n",
        "        print(f\"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "        print(f\"   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(url_results)}\")\n",
        "        print(f\"   –£—Å–ø–µ—à–Ω–æ: {len(successful_results)}\")\n",
        "        print(f\"   –û—à–∏–±–æ–∫: {len(url_results) - len(successful_results)}\")\n",
        "        \n",
        "        if successful_results:\n",
        "            avg_duration = sum(r.get('duration', 0) for r in successful_results) / len(successful_results)\n",
        "            total_duration = sum(r.get('duration', 0) for r in successful_results)\n",
        "            print(f\"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {avg_duration:.2f} —Å–µ–∫\")\n",
        "            print(f\"   –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration:.2f} —Å–µ–∫\")\n",
        "        \n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é\n",
        "        globals()['url_results'] = url_results\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ùå –ê—É–¥–∏–æ URL-—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ TSV —Ñ–∞–π–ª–µ\")\n",
        "        print(\"üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ TSV —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–æ–ª–±—Ü—ã —Å URL-–∞–º–∏\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå TSV —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
        "    print(\"üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ TSV —Ñ–∞–π–ª–∞\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ TSV\n",
        "if 'url_results' in globals() and url_results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üéØ –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –†–ï–ß–ò –ò–ó TSV\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    successful_results = [r for r in url_results if not r.get('error', False)]\n",
        "    error_results = [r for r in url_results if r.get('error', False)]\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    for i, result in enumerate(successful_results, 1):\n",
        "        print(f\"\\n{i}. üîó URL: {result['url'][:60]}...\")\n",
        "        print(f\"   üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\")\n",
        "        print(f\"   \\\"{result['text']}\\\"\")\n",
        "        print(f\"   ‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {result.get('duration', 0):.2f} —Å–µ–∫\")\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
        "        metadata_keys = [k for k in result.keys() if k.startswith('metadata_')]\n",
        "        if metadata_keys:\n",
        "            print(f\"   üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:\")\n",
        "            for key in metadata_keys[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
        "                value = result[key]\n",
        "                if isinstance(value, str) and len(value) > 50:\n",
        "                    value = value[:50] + \"...\"\n",
        "                print(f\"      {key.replace('metadata_', '')}: {value}\")\n",
        "        \n",
        "        print(\"-\" * 60)\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "    if error_results:\n",
        "        print(f\"\\n‚ùå –û–®–ò–ë–ö–ò ({len(error_results)} URL-–æ–≤):\")\n",
        "        for result in error_results:\n",
        "            print(f\"   ‚Ä¢ {result['url'][:60]}...: {result['text']}\")\n",
        "    \n",
        "    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "    print(f\"\\nüìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
        "    print(f\"   üìà –í—Å–µ–≥–æ URL-–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(url_results)}\")\n",
        "    print(f\"   ‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {len(successful_results)}\")\n",
        "    print(f\"   ‚ùå –û—à–∏–±–æ–∫: {len(error_results)}\")\n",
        "    print(f\"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {len(successful_results)/len(url_results)*100:.1f}%\")\n",
        "    \n",
        "    if successful_results:\n",
        "        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "        durations = [r.get('duration', 0) for r in successful_results]\n",
        "        total_duration = sum(durations)\n",
        "        avg_duration = total_duration / len(durations)\n",
        "        \n",
        "        print(f\"   ‚è±Ô∏è  –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {total_duration:.1f} —Å–µ–∫ ({total_duration/60:.1f} –º–∏–Ω)\")\n",
        "        print(f\"   ‚è±Ô∏è  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {avg_duration:.2f} —Å–µ–∫\")\n",
        "        \n",
        "        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–∫—Å—Ç—É\n",
        "        text_lengths = [len(r['text'].split()) for r in successful_results]\n",
        "        avg_words = sum(text_lengths) / len(text_lengths)\n",
        "        total_words = sum(text_lengths)\n",
        "        \n",
        "        print(f\"   üìù –í—Å–µ–≥–æ —Å–ª–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {total_words}\")\n",
        "        print(f\"   üìù –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {avg_words:.1f}\")\n",
        "    \n",
        "    print(\"\\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
        "    \n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "    try:\n",
        "        import json\n",
        "        results_file = os.path.join(DATASET_DIR, \"whisper_results.json\")\n",
        "        \n",
        "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
        "        save_data = {\n",
        "            \"total_processed\": len(url_results),\n",
        "            \"successful\": len(successful_results),\n",
        "            \"errors\": len(error_results),\n",
        "            \"results\": url_results\n",
        "        }\n",
        "        \n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(save_data, f, ensure_ascii=False, indent=2)\n",
        "        \n",
        "        print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {results_file}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL-–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
        "    print(\"üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â—É—é —è—á–µ–π–∫—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –∏–∑ TSV\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper\n",
        "print(\"ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...\")\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_name = \"GPU (CUDA)\" if torch.cuda.is_available() else \"CPU\"\n",
        "print(f\"üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_name}\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏ –º–æ–¥–µ–ª—å\n",
        "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –¥–ª—è –º–æ–¥–µ–ª–∏\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
        "    language=\"russian\", task=\"transcribe\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ –ú–æ–¥–µ–ª—å Whisper —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\")\n",
        "print(f\"üá∑üá∫ –Ø–∑—ã–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: —Ä—É—Å—Å–∫–∏–π\")\n",
        "print(f\"üìä –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~244MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
        "def find_audio_files(directory: str) -> List[str]:\n",
        "    \"\"\"–ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\"\"\"\n",
        "    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac'}\n",
        "    audio_files = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_ext = Path(file).suffix.lower()\n",
        "            \n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
        "            if file_ext in audio_extensions:\n",
        "                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —è–≤–Ω–æ –Ω–µ-–∞—É–¥–∏–æ —Ñ–∞–π–ª—ã\n",
        "                if not any(skip_word in file.lower() for skip_word in ['tsv', 'csv', 'txt', 'json', 'xml']):\n",
        "                    audio_files.append(file_path)\n",
        "                    print(f\"‚úÖ –ù–∞–π–¥–µ–Ω –∞—É–¥–∏–æ—Ñ–∞–π–ª: {file}\")\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª: {file} (–ø–æ—Ö–æ–∂ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π)\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª: {file} (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_ext})\")\n",
        "    \n",
        "    return audio_files\n",
        "\n",
        "# –ò—â–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã\n",
        "audio_files = find_audio_files(DATASET_DIR)\n",
        "\n",
        "print(f\"üîç –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –≤ '{DATASET_DIR}'...\")\n",
        "print(f\"üìä –ù–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤: {len(audio_files)}\")\n",
        "\n",
        "if audio_files:\n",
        "    print(f\"üìù –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:\")\n",
        "    for i, file in enumerate(audio_files[:5]):\n",
        "        print(f\"   {i+1}. {os.path.basename(file)}\")\n",
        "    if len(audio_files) > 5:\n",
        "        print(f\"   ... –∏ –µ—â–µ {len(audio_files) - 5} —Ñ–∞–π–ª–æ–≤\")\n",
        "else:\n",
        "    print(\"‚ùå –ê—É–¥–∏–æ—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\")\n",
        "    print(f\"üìÇ –ü–æ–º–µ—Å—Ç–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É '{DATASET_DIR}/'\")\n",
        "    print(\"üéµ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .wav, .mp3, .flac, .ogg, .m4a, .aac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í—ã–±–æ—Ä —Å–ª—É—á–∞–π–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "def select_random_files(files: List[str], num_samples: int = NUM_SAMPLES) -> List[str]:\n",
        "    \"\"\"–í—ã–±–æ—Ä —Å–ª—É—á–∞–π–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞\"\"\"\n",
        "    random.seed(RANDOM_SEED)\n",
        "    \n",
        "    if len(files) < num_samples:\n",
        "        print(f\"‚ö†Ô∏è  –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {len(files)} —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ\")\n",
        "        return files\n",
        "    \n",
        "    selected = random.sample(files, num_samples)\n",
        "    return selected\n",
        "\n",
        "# –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
        "if audio_files:\n",
        "    selected_files = select_random_files(audio_files, NUM_SAMPLES)\n",
        "    \n",
        "    print(f\"üé≤ –í—ã–±—Ä–∞–Ω–æ {len(selected_files)} —Å–ª—É—á–∞–π–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:\")\n",
        "    for i, file in enumerate(selected_files, 1):\n",
        "        print(f\"   {i}. {os.path.basename(file)}\")\n",
        "else:\n",
        "    selected_files = []\n",
        "    print(\"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ\n",
        "def load_audio(audio_path: str) -> np.ndarray:\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞\"\"\"\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
        "    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac'}\n",
        "    file_ext = Path(audio_path).suffix.lower()\n",
        "    \n",
        "    if file_ext not in audio_extensions:\n",
        "        print(f\"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_ext}\")\n",
        "        return None\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞\n",
        "    filename_lower = os.path.basename(audio_path).lower()\n",
        "    if any(skip_word in filename_lower for skip_word in ['tsv', 'csv', 'txt', 'json', 'xml']):\n",
        "        print(f\"‚ùå –§–∞–π–ª {os.path.basename(audio_path)} –ø–æ—Ö–æ–∂ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å –Ω—É–∂–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏\n",
        "        audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "        \n",
        "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∞—É–¥–∏–æ\n",
        "        max_samples = MAX_AUDIO_LENGTH * SAMPLE_RATE\n",
        "        if len(audio) > max_samples:\n",
        "            audio = audio[:max_samples]\n",
        "            print(f\"‚ö†Ô∏è  –ê—É–¥–∏–æ {os.path.basename(audio_path)} –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ {MAX_AUDIO_LENGTH} —Å–µ–∫\")\n",
        "        \n",
        "        return audio\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def transcribe_audio(audio_path: str) -> Dict[str, str]:\n",
        "    \"\"\"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ –∞—É–¥–∏–æ—Ñ–∞–π–ª–µ\"\"\"\n",
        "    print(f\"üéµ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {os.path.basename(audio_path)}\")\n",
        "    \n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ\n",
        "    audio = load_audio(audio_path)\n",
        "    if audio is None:\n",
        "        return {\"file\": os.path.basename(audio_path), \"text\": \"–û–®–ò–ë–ö–ê –ó–ê–ì–†–£–ó–ö–ò\", \"error\": True}\n",
        "    \n",
        "    try:\n",
        "        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "        input_features = processor(\n",
        "            audio, \n",
        "            sampling_rate=SAMPLE_RATE, \n",
        "            return_tensors=\"pt\"\n",
        "        ).input_features.to(device)\n",
        "        \n",
        "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = model.generate(input_features)\n",
        "        \n",
        "        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        transcription = processor.batch_decode(\n",
        "            predicted_ids, \n",
        "            skip_special_tokens=True\n",
        "        )[0]\n",
        "        \n",
        "        return {\n",
        "            \"file\": os.path.basename(audio_path),\n",
        "            \"text\": transcription.strip(),\n",
        "            \"error\": False,\n",
        "            \"audio_path\": audio_path\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {audio_path}: {e}\")\n",
        "        return {\"file\": os.path.basename(audio_path), \"text\": f\"–û–®–ò–ë–ö–ê: {str(e)}\", \"error\": True}\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤\n",
        "if selected_files:\n",
        "    print(\"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i, audio_file in enumerate(selected_files, 1):\n",
        "        print(f\"\\nüìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª {i}/{len(selected_files)}\")\n",
        "        result = transcribe_audio(audio_file)\n",
        "        results.append(result)\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É\n",
        "        if not result.get('error', False):\n",
        "            print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result['text']}\")\n",
        "        else:\n",
        "            print(f\"‚ùå {result['text']}\")\n",
        "        \n",
        "        print(\"-\" * 40)\n",
        "    \n",
        "    print(f\"\\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} —Ñ–∞–π–ª–æ–≤\")\n",
        "    \n",
        "else:\n",
        "    results = []\n",
        "    print(\"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "if results:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üéØ –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø –†–ï–ß–ò\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    successful_results = [r for r in results if not r.get('error', False)]\n",
        "    error_results = [r for r in results if r.get('error', False)]\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    for i, result in enumerate(successful_results, 1):\n",
        "        print(f\"\\n{i}. üìÅ –§–∞–π–ª: {result['file']}\")\n",
        "        print(f\"   üìù –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\")\n",
        "        print(f\"   \\\"{result['text']}\\\"\")\n",
        "        print(\"-\" * 50)\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "    if error_results:\n",
        "        print(f\"\\n‚ùå –û–®–ò–ë–ö–ò ({len(error_results)} —Ñ–∞–π–ª–æ–≤):\")\n",
        "        for result in error_results:\n",
        "            print(f\"   ‚Ä¢ {result['file']}: {result['text']}\")\n",
        "    \n",
        "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "    print(f\"\\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
        "    print(f\"   üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)}\")\n",
        "    print(f\"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(successful_results)}\")\n",
        "    print(f\"   ‚ùå –û—à–∏–±–æ–∫: {len(error_results)}\")\n",
        "    print(f\"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {len(successful_results)/len(results)*100:.1f}%\")\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∞—É–¥–∏–æ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)\n",
        "    print(f\"\\nüéµ –ü–†–ò–ú–ï–†–´ –ê–£–î–ò–û:\")\n",
        "    for i, result in enumerate(successful_results[:3], 1):\n",
        "        if 'audio_path' in result and os.path.exists(result['audio_path']):\n",
        "            print(f\"\\n{i}. {result['file']}:\")\n",
        "            print(f\"   –¢–µ–∫—Å—Ç: \\\"{result['text']}\\\"\")\n",
        "            try:\n",
        "                display(Audio(result['audio_path']))\n",
        "            except:\n",
        "                print(\"   (–ê—É–¥–∏–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è)\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n",
        "\n",
        "### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–µ–º–æ-–∞—É–¥–∏–æ\n",
        "–ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –º–æ–∂–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –¥–µ–º–æ-—Ñ–∞–π–ª–∞—Ö:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ TSV\n",
        "if 'tsv_audio_paths' in globals() and tsv_audio_paths and metadata_df is not None:\n",
        "    print(\"üöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ TSV...\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ TSV\n",
        "    import random\n",
        "    random.seed(RANDOM_SEED)\n",
        "    test_files = random.sample(tsv_audio_paths, min(5, len(tsv_audio_paths)))\n",
        "    \n",
        "    metadata_results = []\n",
        "    \n",
        "    for i, audio_file in enumerate(test_files, 1):\n",
        "        print(f\"\\nüìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª {i}/{len(test_files)}\")\n",
        "        result = process_audio_with_metadata(audio_file, metadata_df)\n",
        "        metadata_results.append(result)\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
        "        if not result.get('error', False):\n",
        "            print(f\"‚úÖ Whisper —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result['text']}\")\n",
        "            \n",
        "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "            metadata_keys = [k for k in result.keys() if k.startswith('metadata_')]\n",
        "            if metadata_keys:\n",
        "                print(f\"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:\")\n",
        "                for key in metadata_keys:\n",
        "                    print(f\"   {key.replace('metadata_', '')}: {result[key]}\")\n",
        "                \n",
        "                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å ground truth –µ—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n",
        "                ground_truth_key = next((k for k in metadata_keys if 'text' in k or 'transcript' in k), None)\n",
        "                if ground_truth_key:\n",
        "                    ground_truth = result[ground_truth_key]\n",
        "                    comparison = compare_with_ground_truth(result['text'], ground_truth)\n",
        "                    \n",
        "                    print(f\"üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º:\")\n",
        "                    print(f\"   Jaccard similarity: {comparison['jaccard_similarity']:.3f}\")\n",
        "                    print(f\"   –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–ª–∏–Ω: {comparison['length_ratio']:.3f}\")\n",
        "                    print(f\"   –°–ª–æ–≤ Whisper: {comparison['whisper_words']}\")\n",
        "                    print(f\"   –°–ª–æ–≤ —ç—Ç–∞–ª–æ–Ω: {comparison['truth_words']}\")\n",
        "            else:\n",
        "                print(\"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
        "        else:\n",
        "            print(f\"‚ùå {result['text']}\")\n",
        "        \n",
        "        print(\"-\" * 50)\n",
        "    \n",
        "    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "    successful_results = [r for r in metadata_results if not r.get('error', False)]\n",
        "    if successful_results:\n",
        "        print(f\"\\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
        "        print(f\"   –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful_results)}/{len(metadata_results)}\")\n",
        "        \n",
        "        # –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "        comparisons = []\n",
        "        for result in successful_results:\n",
        "            ground_truth_key = next((k for k in result.keys() if k.startswith('metadata_') and ('text' in k or 'transcript' in k)), None)\n",
        "            if ground_truth_key:\n",
        "                comparison = compare_with_ground_truth(result['text'], result[ground_truth_key])\n",
        "                comparisons.append(comparison)\n",
        "        \n",
        "        if comparisons:\n",
        "            avg_jaccard = sum(c['jaccard_similarity'] for c in comparisons) / len(comparisons)\n",
        "            avg_length_ratio = sum(c['length_ratio'] for c in comparisons) / len(comparisons)\n",
        "            \n",
        "            print(f\"   –°—Ä–µ–¥–Ω—è—è Jaccard similarity: {avg_jaccard:.3f}\")\n",
        "            print(f\"   –°—Ä–µ–¥–Ω–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–ª–∏–Ω: {avg_length_ratio:.3f}\")\n",
        "\n",
        "elif 'selected_files' in globals() and selected_files:\n",
        "    print(\"‚ö†Ô∏è  TSV –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É\")\n",
        "    print(\"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª urls_normalized.tsv –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ dataset/\")\n",
        "else:\n",
        "    print(\"‚ùå –ù–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
        "    print(\"üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —è—á–µ–π–∫–∏\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–∞—É–¥–∏–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "def create_demo_audio():\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –¥–µ–º–æ-–∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\"\"\"\n",
        "    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–æ–Ω (440 Hz - –Ω–æ—Ç–∞ –õ—è)\n",
        "    duration = 3  # —Å–µ–∫—É–Ω–¥—ã\n",
        "    sample_rate = 16000\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
        "    frequency = 440  # Hz\n",
        "    audio_data = np.sin(2 * np.pi * frequency * t)\n",
        "    \n",
        "    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞—Ç—É—Ö–∞–Ω–∏–µ\n",
        "    fade_samples = int(0.1 * sample_rate)  # 0.1 —Å–µ–∫—É–Ω–¥—ã –∑–∞—Ç—É—Ö–∞–Ω–∏—è\n",
        "    audio_data[:fade_samples] *= np.linspace(0, 1, fade_samples)\n",
        "    audio_data[-fade_samples:] *= np.linspace(1, 0, fade_samples)\n",
        "    \n",
        "    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16\n",
        "    audio_data = (audio_data * 32767).astype(np.int16)\n",
        "    \n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª\n",
        "    demo_path = os.path.join(DATASET_DIR, \"demo_tone.wav\")\n",
        "    write(demo_path, sample_rate, audio_data)\n",
        "    \n",
        "    return demo_path\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-—Ñ–∞–π–ª –µ—Å–ª–∏ –Ω–µ—Ç –¥—Ä—É–≥–∏—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤\n",
        "if not audio_files:\n",
        "    print(\"üéµ –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...\")\n",
        "    try:\n",
        "        from scipy.io.wavfile import write\n",
        "        demo_file = create_demo_audio()\n",
        "        print(f\"‚úÖ –°–æ–∑–¥–∞–Ω –¥–µ–º–æ-—Ñ–∞–π–ª: {demo_file}\")\n",
        "        print(\"‚ö†Ô∏è  –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: —ç—Ç–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç–æ–Ω, –Ω–µ —Ä–µ—á—å\")\n",
        "    except ImportError:\n",
        "        print(\"‚ùå –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–º–æ-—Ñ–∞–π–ª–∞ –Ω—É–∂–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ scipy\")\n",
        "        print(\"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scipy\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–º–æ-—Ñ–∞–π–ª–∞: {e}\")\n",
        "else:\n",
        "    print(\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –Ω–∞–π–¥–µ–Ω, –¥–µ–º–æ-—Ñ–∞–π–ª –Ω–µ –Ω—É–∂–µ–Ω\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ —Å torchaudio\n",
        "# –≠—Ç–∞ —è—á–µ–π–∫–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥—Ä—É–∑–∫—É –∏ –ø–µ—Ä–µ—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        "\n",
        "if 'selected_files' in globals() and selected_files:\n",
        "    print(\"üöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∞—É–¥–∏–æ —Å torchaudio...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ñ–∞–π–ª–∞\n",
        "    test_files = selected_files[:3]\n",
        "    \n",
        "    for i, audio_file in enumerate(test_files, 1):\n",
        "        print(f\"\\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª {i}/{len(test_files)}: {os.path.basename(audio_file)}\")\n",
        "        \n",
        "        wav, sr = load_audio_with_torchaudio(audio_file)\n",
        "        \n",
        "        if wav is not None and sr is not None:\n",
        "            print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!\")\n",
        "            print(f\"   –§–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞: {wav.shape}\")\n",
        "            print(f\"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {sr} Hz\")\n",
        "            print(f\"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {wav.shape[1] / sr:.2f} —Å–µ–∫\")\n",
        "            print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤: {wav.shape[0]}\")\n",
        "        else:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏\")\n",
        "        \n",
        "        print(\"-\" * 40)\n",
        "    \n",
        "    print(f\"\\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "    \n",
        "elif 'audio_files' in globals() and audio_files:\n",
        "    print(\"üöÄ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞—Ö...\")\n",
        "    test_files = audio_files[:3]\n",
        "    \n",
        "    for i, audio_file in enumerate(test_files, 1):\n",
        "        print(f\"\\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª {i}/{len(test_files)}: {os.path.basename(audio_file)}\")\n",
        "        \n",
        "        wav, sr = load_audio_with_torchaudio(audio_file)\n",
        "        \n",
        "        if wav is not None and sr is not None:\n",
        "            print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!\")\n",
        "            print(f\"   –§–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞: {wav.shape}\")\n",
        "            print(f\"   –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {sr} Hz\")\n",
        "            print(f\"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {wav.shape[1] / sr:.2f} —Å–µ–∫\")\n",
        "        else:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏\")\n",
        "        \n",
        "        print(\"-\" * 40)\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå –ù–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
        "    print(\"üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —è—á–µ–π–∫–∏ –∏–ª–∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É 'dataset/'\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
